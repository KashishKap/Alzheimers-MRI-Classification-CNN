{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77d73ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import InceptionV3, ResNet50, VGG16\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4bbd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "SEED = 1888\n",
    "IMG_SIZE = [176, 208]\n",
    "BATCH_SIZE = 32\n",
    "CLASS_LIST = ['Mild_Demented', 'Moderate_Demented', 'Non_Demented', 'Very_Mild_Demented']\n",
    "DIR_INPUT = './data-initial/Dataset/'\n",
    "DIR_WORK = './'\n",
    "DIR_MODELS = os.path.join(DIR_WORK, 'models')\n",
    "DIR_TRAIN = os.path.join(DIR_WORK, 'resampled', 'train')\n",
    "DIR_VAL = os.path.join(DIR_WORK, 'resampled', 'val')\n",
    "DIR_TEST = os.path.join(DIR_WORK, 'resampled', 'test')\n",
    "\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74789a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_gen = train_datagen.flow_from_directory(\n",
    "    DIR_TRAIN,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "val_gen = val_datagen.flow_from_directory(\n",
    "    DIR_VAL,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "test_gen = val_datagen.flow_from_directory(\n",
    "    DIR_TEST,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    seed=SEED,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9736f22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define metrics\n",
    "metrics = [tf.keras.metrics.AUC(name=f'auc_{class_name}') for class_name in CLASS_LIST]\n",
    "\n",
    "# Define the build_transfer_model function\n",
    "def build_transfer_model(conv_base, dropout, dense_nodes, learn_rate, metrics):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(conv_base)\n",
    "    model.add(tf.keras.layers.GlobalAveragePooling2D())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(tf.keras.layers.Dense(dense_nodes, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(dropout))\n",
    "    model.add(tf.keras.layers.Dense(len(metrics), activation='softmax'))\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learn_rate), \n",
    "                  loss='categorical_crossentropy', \n",
    "                  metrics=metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e65f7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune the pretrained model\n",
    "def fine_tune_model(model, trainable_layers):\n",
    "    for layer in model.layers[-trainable_layers:]:\n",
    "        if not isinstance(layer, BatchNormalization):\n",
    "            layer.trainable = True\n",
    "\n",
    "# Function to plot training metrics\n",
    "def plot_training_metrics(history, model, test_gen, y_actual, y_pred, class_list):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, acc, 'b', label='Training acc')\n",
    "    plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    print(classification_report(y_actual, y_pred, target_names=class_list))\n",
    "    cm = confusion_matrix(y_actual, y_pred)\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title('Confusion matrix')\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(class_list))\n",
    "    plt.xticks(tick_marks, class_list, rotation=45)\n",
    "    plt.yticks(tick_marks, class_list)\n",
    "\n",
    "    fmt = 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570df1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Model 2: GoogleNet\n",
    "# Get base\n",
    "conv_base_google = InceptionV3(weights='imagenet', include_top=False, input_shape=(*IMG_SIZE, 3))\n",
    "\n",
    "# Fine-tune the top layers of the InceptionV3 base\n",
    "fine_tune_model(conv_base_google, trainable_layers=100)\n",
    "\n",
    "# Build and compile the model\n",
    "model_google = build_transfer_model(conv_base_google, dropout=0.5, dense_nodes=624, learn_rate=0.00001, metrics=metrics)\n",
    "\n",
    "# Train\n",
    "EPOCHS_GOOGLE = 100 \n",
    "tic_google = time.perf_counter()\n",
    "history_google = model_google.fit(\n",
    "    train_gen,\n",
    "    epochs=EPOCHS_GOOGLE,\n",
    "    validation_data=val_gen,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Get class predictions\n",
    "y_prob_google = model_google.predict(test_gen)\n",
    "y_pred_google = y_prob_google.argmax(axis=-1)\n",
    "\n",
    "# Get actual classes\n",
    "y_actual_google = test_gen.classes\n",
    "\n",
    "# Plot training metrics for GoogleNet model\n",
    "plot_training_metrics(history_google, model_google, test_gen, y_actual_google, y_pred_google, CLASS_LIST)\n",
    "\n",
    "# Compute OvA AUC for each class for GoogleNet\n",
    "y_one_hot_google = label_binarize(y_actual_google, classes=np.arange(len(CLASS_LIST)))\n",
    "y_prob_google = model_google.predict(test_gen)\n",
    "for i, class_name in enumerate(CLASS_LIST):\n",
    "    auc_value = roc_auc_score(y_one_hot_google[:, i], y_prob_google[:, i])\n",
    "    print(f'OvA AUC for {class_name}: {auc_value}')\n",
    "\n",
    "# Save Model\n",
    "model_google.save(os.path.join(DIR_MODELS, 'model_google'))\n",
    "\n",
    "# Time\n",
    "toc_google = time.perf_counter()\n",
    "print(\"Total Time for GoogleNet: {} mins\".format(round((toc_google-tic_google)/60, 2)))\n",
    "\n",
    "# Custom Model 3: Vision Transformer\n",
    "# Use a suitable implementation for Vision Transformer\n",
    "class VisionTransformer(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(VisionTransformer, self).__init__()\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.dense = tf.keras.layers.Dense(len(CLASS_LIST), activation='softmax')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.flatten(inputs)\n",
    "        return self.dense(x)\n",
    "\n",
    "conv_base_vit = VisionTransformer()\n",
    "\n",
    "# Build and compile the model\n",
    "model_vit = build_transfer_model(conv_base_vit, dropout=0.5, dense_nodes=624, learn_rate=0.00001, metrics=metrics)\n",
    "\n",
    "# Train\n",
    "EPOCHS_VIT = 100 \n",
    "tic_vit = time.perf_counter()\n",
    "history_vit = model_vit.fit(\n",
    "    train_gen,\n",
    "    epochs=EPOCHS_VIT,\n",
    "    validation_data=val_gen,\n",
    "    verbose=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce530e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get class predictions\n",
    "y_prob_vit = model_vit.predict(test_gen)\n",
    "y_pred_vit = y_prob_vit.argmax(axis=-1)\n",
    "\n",
    "# Get actual classes\n",
    "y_actual_vit = test_gen.classes\n",
    "\n",
    "# Plot training metrics for Vision Transformer model\n",
    "plot_training_metrics(history_vit, model_vit, test_gen, y_actual_vit, y_pred_vit, CLASS_LIST)\n",
    "\n",
    "# Compute OvA AUC for each class for Vision Transformer\n",
    "y_one_hot_vit = label_binarize(y_actual_vit, classes=np.arange(len(CLASS_LIST)))\n",
    "y_prob_vit = model_vit.predict(test_gen)\n",
    "for i, class_name in enumerate(CLASS_LIST):\n",
    "    auc_value = roc_auc_score(y_one_hot_vit[:, i], y_prob_vit[:, i])\n",
    "    print(f'OvA AUC for {class_name}: {auc_value}')\n",
    "\n",
    "# Save Model\n",
    "model_vit.save(os.path.join(DIR_MODELS, 'model_vit'))\n",
    "\n",
    "# Time\n",
    "toc_vit = time.perf_counter()\n",
    "print(\"Total Time for Vision Transformer: {} mins\".format(round((toc_vit-tic_vit)/60, 2)))\n",
    "\n",
    "# Custom Model 4: ResNet34\n",
    "# Get base\n",
    "conv_base_resnet34 = ResNet50(weights='imagenet', include_top=False, input_shape=(*IMG_SIZE, 3))\n",
    "\n",
    "# Fine-tune the top layers of the ResNet34 base\n",
    "fine_tune_model(conv_base_resnet34, trainable_layers=100)\n",
    "\n",
    "# Build and compile the model\n",
    "model_resnet34 = build_transfer_model(conv_base_resnet34, dropout=0.5, dense_nodes=624, learn_rate=0.00001, metrics=metrics)\n",
    "\n",
    "# Train\n",
    "EPOCHS_RESNET34 = 100 \n",
    "tic_resnet34 = time.perf_counter()\n",
    "history_resnet34 = model_resnet34.fit(\n",
    "    train_gen,\n",
    "    epochs=EPOCHS_RESNET34,\n",
    "    validation_data=val_gen,\n",
    "    verbose=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15a03cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get class predictions\n",
    "y_prob_resnet34 = model_resnet34.predict(test_gen)\n",
    "y_pred_resnet34 = y_prob_resnet34.argmax(axis=-1)\n",
    "\n",
    "# Get actual classes\n",
    "y_actual_resnet34 = test_gen.classes\n",
    "\n",
    "# Plot training metrics for ResNet34 model\n",
    "plot_training_metrics(history_resnet34, model_resnet34, test_gen, y_actual_resnet34, y_pred_resnet34, CLASS_LIST)\n",
    "\n",
    "# Compute OvA AUC for each class for ResNet34\n",
    "y_one_hot_resnet34 = label_binarize(y_actual_resnet34, classes=np.arange(len(CLASS_LIST)))\n",
    "y_prob_resnet34 = model_resnet34.predict(test_gen)\n",
    "for i, class_name in enumerate(CLASS_LIST):\n",
    "    auc_value = roc_auc_score(y_one_hot_resnet34[:, i], y_prob_resnet34[:, i])\n",
    "    print(f'OvA AUC for {class_name}: {auc_value}')\n",
    "\n",
    "# Save Model\n",
    "model_resnet34.save(os.path.join(DIR_MODELS, 'model_resnet34'))\n",
    "\n",
    "# Time\n",
    "toc_resnet34 = time.perf_counter()\n",
    "print(\"Total Time for ResNet34: {} mins\".format(round((toc_resnet34-tic_resnet34)/60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8078d193",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07516bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "SEED = 1888\n",
    "IMG_SIZE = [176, 208]\n",
    "BATCH_SIZE = 32\n",
    "CLASS_LIST = ['Mild_Demented', 'Moderate_Demented', 'Non_Demented', 'Very_Mild_Demented']\n",
    "DIR_INPUT = './data-initial/Dataset/'\n",
    "DIR_WORK = './'\n",
    "DIR_MODELS = os.path.join(DIR_WORK, 'models')\n",
    "DIR_TRAIN = os.path.join(DIR_WORK, 'resampled', 'train')\n",
    "DIR_VAL = os.path.join(DIR_WORK, 'resampled', 'val')\n",
    "DIR_TEST = os.path.join(DIR_WORK, 'resampled', 'test')\n",
    "\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fd81e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_gen = train_datagen.flow_from_directory(\n",
    "    DIR_TRAIN,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "val_gen = val_datagen.flow_from_directory(\n",
    "    DIR_VAL,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "test_gen = val_datagen.flow_from_directory(\n",
    "    DIR_TEST,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    seed=SEED,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fed929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define metrics\n",
    "metrics = [tf.keras.metrics.AUC(name=f'auc_{class_name}') for class_name in CLASS_LIST]\n",
    "\n",
    "# Define the build_transfer_model function\n",
    "def build_transfer_model(conv_base, dropout, dense_nodes, learn_rate, metrics):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(conv_base)\n",
    "    model.add(tf.keras.layers.GlobalAveragePooling2D())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(tf.keras.layers.Dense(dense_nodes, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(dropout))\n",
    "    model.add(tf.keras.layers.Dense(len(metrics), activation='softmax'))\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learn_rate), \n",
    "                  loss='categorical_crossentropy', \n",
    "                  metrics=metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ac280f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune the pretrained model\n",
    "def fine_tune_model(model, trainable_layers):\n",
    "    for layer in model.layers[-trainable_layers:]:\n",
    "        if not isinstance(layer, BatchNormalization):\n",
    "            layer.trainable = True\n",
    "\n",
    "# First Custom Model: Base + Additional Capacity (93 epochs)\n",
    "# Get base\n",
    "conv_base = InceptionV3(weights='imagenet', include_top=False, input_shape=(*IMG_SIZE, 3))\n",
    "\n",
    "# Fine-tune the top layers of the InceptionV3 base\n",
    "fine_tune_model(conv_base, trainable_layers=100)\n",
    "\n",
    "# Build and compile the model\n",
    "model_93 = build_transfer_model(conv_base, dropout=0.5, dense_nodes=624, learn_rate=0.00001, metrics=metrics)\n",
    "\n",
    "# Train\n",
    "EPOCHS_93 = 110 \n",
    "tic = time.perf_counter()\n",
    "history_93 = model_93.fit(\n",
    "    train_gen,\n",
    "    epochs=EPOCHS_93,\n",
    "    validation_data=val_gen,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095e723c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get class predictions\n",
    "y_prob_93 = model_93.predict(test_gen)\n",
    "y_pred_93 = y_prob_93.argmax(axis=-1)\n",
    "\n",
    "# Get actual classes\n",
    "y_actual_93 = test_gen.classes\n",
    "\n",
    "# Function to plot training metrics\n",
    "def plot_training_metrics(train_hist, model, test_gen, y_actual, y_pred, classes):\n",
    "    test_results = model.evaluate(test_gen, verbose=False)\n",
    "    test_loss = test_results[0]\n",
    "    test_metric = test_results[1]  # Adjust this if the relevant metric is at a different index\n",
    "    results = round(test_metric, 2) * 100\n",
    "    results_title = \"\\n Model AUC on Test Data: {}%\".format(results)\n",
    "    print(results_title)\n",
    "    print(len(results_title) * \"-\")\n",
    "    print(classification_report(y_actual, y_pred, target_names=classes))\n",
    "    history_dict = train_hist.history\n",
    "    loss_values = history_dict['loss']\n",
    "    val_loss_values = history_dict['val_loss']\n",
    "    \n",
    "    # Combine AUC values for all classes\n",
    "    auc_values = [history_dict[f'auc_{class_name}'] for class_name in classes]\n",
    "    val_auc_values = [history_dict[f'val_auc_{class_name}'] for class_name in classes]\n",
    "    \n",
    "    # Calculate mean AUC across all classes\n",
    "    mean_auc_values = np.mean(auc_values, axis=0)\n",
    "    mean_val_auc_values = np.mean(val_auc_values, axis=0)\n",
    "    \n",
    "    epochs = range(1, len(history_dict[f'auc_{classes[0]}']) + 1)\n",
    "    max_auc = np.max(mean_val_auc_values)\n",
    "    min_loss = np.min(val_loss_values)\n",
    "\n",
    "    plt.subplots(figsize=(12, 4))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(epochs, loss_values, 'bo', label='Training loss')\n",
    "    plt.plot(epochs, val_loss_values, 'cornflowerblue', label='Validation loss')\n",
    "    plt.title('Validation Loss by Epochs')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.axhline(y=min_loss, color='darkslategray', linestyle='--')\n",
    "    plt.legend()\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(epochs, mean_auc_values, 'bo', label='Training AUC')\n",
    "    plt.plot(epochs, mean_val_auc_values, 'cornflowerblue', label='Validation AUC')\n",
    "    plt.plot(epochs, [results / 100] * len(epochs), 'darkmagenta', linestyle='--', label='Test AUC')\n",
    "    plt.title('Validation AUC by Epochs')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('AUC')\n",
    "    plt.axhline(y=max_auc, color='darkslategray', linestyle='--')\n",
    "    plt.legend()\n",
    "\n",
    "    cm = confusion_matrix(y_actual, y_pred)\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.BuPu)\n",
    "    plt.title(\"Confusion Matrix \\n AUC:{}%\".format(results))\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    threshold = cm.max() / 2.\n",
    "    for r, c in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(c, r, format(cm[r, c], 'd'), horizontalalignment=\"center\", color=\"white\" if cm[r, c] > threshold else \"black\")\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot training metrics\n",
    "plot_training_metrics(history_93, model_93, test_gen, y_actual_93, y_pred_93, CLASS_LIST)\n",
    "\n",
    "# Compute OvA AUC for each class\n",
    "class_names = CLASS_LIST\n",
    "\n",
    "y_one_hot_93 = label_binarize(y_actual_93, classes=np.arange(len(class_names)))\n",
    "y_prob_93 = model_93.predict(test_gen)\n",
    "for i, class_name in enumerate(class_names):\n",
    "    auc_value = roc_auc_score(y_one_hot_93[:, i], y_prob_93[:, i])\n",
    "    print(f'OvA AUC for {class_name}: {auc_value}')\n",
    "\n",
    "# Save Model\n",
    "model_93.save(os.path.join(DIR_MODELS, 'model_custom_93_epochs'))\n",
    "\n",
    "# Time\n",
    "toc = time.perf_counter()\n",
    "print(\"Total Time for 93 Epochs: {} mins\".format(round((toc-tic)/60, 2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4cc6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "from os import path\n",
    "import shutil\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from PIL import Image, ImageTk\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfa752f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "model_path = os.path.join('models', 'model_added_capacity')\n",
    "# Update with the actual path to your model\n",
    "model = load_model(model_path)\n",
    "\n",
    "# Function to preprocess the uploaded image and make a prediction\n",
    "def predict_image():\n",
    "    file_path = filedialog.askopenfilename(\n",
    "        title=\"Select MRI Image\",\n",
    "    )\n",
    "\n",
    "    if file_path:\n",
    "        img = image.load_img(file_path, target_size=(176, 208))\n",
    "        img_array = image.img_to_array(img)\n",
    "        img_array = np.expand_dims(img_array, axis=0)\n",
    "        img_array /= 255.0  # Normalize pixel values to the range [0, 1]\n",
    "\n",
    "        result = model.predict(img_array)\n",
    "        result_class = np.argmax(result)\n",
    "        class_names = ['Mild Demented', 'Moderate Demented', 'Non Demented', 'Very Mild Demented']\n",
    "        result_text.set(f\"Prediction: {class_names[result_class]}\")\n",
    "\n",
    "        # Display the uploaded image\n",
    "        img = Image.open(file_path)\n",
    "        img = img.resize((200, 150))\n",
    "        img = ImageTk.PhotoImage(img)\n",
    "        image_label.config(image=img)\n",
    "        image_label.image = img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f41c0f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kashishkapoor/anaconda3/lib/python3.11/tkinter/__init__.py\", line 1948, in __call__\n",
      "    return self.func(*args)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/w5/_vl7tvj16f7c3190jn_03clc0000gn/T/ipykernel_87618/786032371.py\", line 26, in predict_image\n",
      "    img = image.load_img(file_path, target_size=(176, 208))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kashishkapoor/anaconda3/lib/python3.11/site-packages/keras/src/utils/image_utils.py\", line 423, in load_img\n",
      "    img = pil_image.open(io.BytesIO(f.read()))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kashishkapoor/anaconda3/lib/python3.11/site-packages/PIL/Image.py\", line 3283, in open\n",
      "    raise UnidentifiedImageError(msg)\n",
      "PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x2992da8e0>\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kashishkapoor/anaconda3/lib/python3.11/tkinter/__init__.py\", line 1948, in __call__\n",
      "    return self.func(*args)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/w5/_vl7tvj16f7c3190jn_03clc0000gn/T/ipykernel_87618/786032371.py\", line 26, in predict_image\n",
      "    img = image.load_img(file_path, target_size=(176, 208))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kashishkapoor/anaconda3/lib/python3.11/site-packages/keras/src/utils/image_utils.py\", line 423, in load_img\n",
      "    img = pil_image.open(io.BytesIO(f.read()))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kashishkapoor/anaconda3/lib/python3.11/site-packages/PIL/Image.py\", line 3283, in open\n",
      "    raise UnidentifiedImageError(msg)\n",
      "PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x2c251db20>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 610ms/step\n"
     ]
    }
   ],
   "source": [
    "# Create the main GUI window\n",
    "root = tk.Tk()\n",
    "root.title(\"Alzheimer's Detection\")\n",
    "\n",
    "# Create GUI components\n",
    "upload_button = tk.Button(root, text=\"Upload MRI Image\", command=predict_image, bg = \"red\")\n",
    "result_text = tk.StringVar()\n",
    "result_label = tk.Label(root, textvariable=result_text, font=(\"Helvetica\", 14))\n",
    "image_label = tk.Label(root)\n",
    "\n",
    "# Pack GUI components\n",
    "upload_button.pack(pady=10)\n",
    "result_label.pack(pady=10)\n",
    "image_label.pack(pady=10)\n",
    "\n",
    "# Run the GUI application\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d15ed70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
